[[File:solidscience.jpg|400px|thumb|right|Solid Science: Research Methods]]
**[Solid Science: Research Methods](https://class.coursera.org/solidsciencemethods-001)**

*Offered by: [University of Amsterdam](https://www.coursera.org/amsterdam)*

*Instructor: [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)*

<span style="color:white;">.</span>

Welcome to the Wiki page for **[Solid Science: Research Methods](https://class.coursera.org/solidsciencemethods-001)** course!

Feel free to edit any of the existing sections or to create new ones as well as new pages. I just started because some people wanted to participate but didn't know why.

Remember, we all benefit from a clean and organized page!

If you have any questions about editing/creating a wiki page, click [Help](https://share.coursera.org/wiki/index.php/Help:Editing) on the left navigation bar or post a question in the forum. I'm sure someone from the team or student will answer! 

Best regards, *[Nuno Fernandes](https://class.coursera.org/solidsciencemethods-001/forum/profile?user_id=5612778)*

<span style="color:white;">.</span>


#Module 1: Origins of the scientific method

+ **[Video Lecture Transcripts - Module 1 (download link)](https://copy.com/WQt0HMzp1N43kxZx)**

<span style="color:white;">.</span>

##1.01 Non-scientific methods

+ **[[Solidsciencemethods-001:1.01transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

+ **[[Solidsciencemethods-001:1.01michaelnew | Highly Idiosyncratic Notes]]** by [Michael New](https://class.coursera.org/solidsciencemethods-001/forum/profile?user_id=1980493)

>>>*"Whether the apple actually fell on Newton’s head or not, intuition, I believe, played a part in his first thoughts about the nature of forces, including gravitational."* [[Solidsciencemethods-001:1.01michaelnew | Read more]]


+ **[[Solidsciencemethods-001:1.01nfernandes | Day-to-day Knowledge vs Scientific Knowledge]]** by [Nuno Fernandes](https://class.coursera.org/solidsciencemethods-001/forum/profile?user_id=5612778)

>>> *"So, what do we need to create knowledge? Is it enough to observe?"* [[Solidsciencemethods-001:1.01nfernandes | Read more]]

<span style="color:white;">.</span>


##1.02 Scientific method

+ **[[Solidsciencemethods-001:1.02transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

+ **[[Solidsciencemethods-001:1.02nfernandes | Is your study scientific?]]** by [Nuno Fernandes](https://class.coursera.org/solidsciencemethods-001/forum/profile?user_id=5612778)

>>> *"When applying the scientific method, check for these principles"*

[[File:6_principles.png|400px|thumb|center|Is your study scientific?]]

> - All 6 principles respected/comprised → **scientific method** → can be compared to and compete with other scientific claims (by **Carolina Reimão Doria**)

<span style="color:white;">.</span>


##1.03 Scientific claims

+ **[[Solidsciencemethods-001:1.03transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

+ **[[Solidsciencemethods-001:1.03carolinareimaodoria | Scientific claims: a brief glossary]]** by **Carolina Reimão Doria**


>>> *"Some claims are more certain than others because they are better supported by evidence"* [[Solidsciencemethods-001:1.03carolinareimaodoria | Read more]]

<span style="color:white;">.</span>


##1.04 Classical period

+ **[[Solidsciencemethods-001:1.04transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

+ **[[Solidsciencemethods-001:1.04nfernandes | A chronology of the scientific evolution regarding the classical period until 16th-17 c.]]** by [Nuno Fernandes](https://class.coursera.org/solidsciencemethods-001/forum/profile?user_id=5612778)

[[File:classicalperiod.png|400px|thumb|center|A chronology of the scientific evolution]]

<span style="color:white;">.</span>


##1.05 Enlightenment

+ **[[Solidsciencemethods-001:1.05transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

+ **[[Solidsciencemethods-001:1.05nfernandes | Enlightenment: key ideas]]** by [Nuno Fernandes](https://class.coursera.org/solidsciencemethods-001/forum/profile?user_id=5612778)

+ **[[Solidsciencemethods-001:1.05nfernandes2 | Induction and Deduction: a clarification of concepts]]** by [Nuno Fernandes](https://class.coursera.org/solidsciencemethods-001/forum/profile?user_id=5612778)

>>>*"Induction and deduction are two, usually different but never contradictory, approaches to problem solving."* [[Solidsciencemethods-001:1.05nfernandes2 | Read more]]

<span style="color:white;">.</span>

##1.06 Modern science

+ **[[Solidsciencemethods-001:1.061transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)
* **[[Kuhn vs. Popper]]** by [Marcus Birkenkrahe](https://class.coursera.org/solidsciencemethods-001/forum/profile?user_id=4983046)

<span style="color:white;">.</span>

##1.07 Epistemology

+ **[[Solidsciencemethods-001:1.07transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

+ **[[Solidsciencemethods-001:1.07nfernandes | Philosophy of Research: Epistemology]]** by [Nuno Fernandes](https://class.coursera.org/solidsciencemethods-001/forum/profile?user_id=5612778)

[[File:epistemology.png|400px|thumb|center|Philosophy of Research: Epistemology]]


<span style="color:white;">.</span>

##1.08 Ontology

+ **[[Solidsciencemethods-001:1.08transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

+ **[[Solidsciencemethods-001:1.08nfernandes | Philosophy of Research: Ontology]]** by [Nuno Fernandes](https://class.coursera.org/solidsciencemethods-001/forum/profile?user_id=5612778)

[[File:ontology.png|400px|thumb|center|Philosophy of Research: Ontology]]

<span style="color:white;">.</span>

##1.09 Approaches

+ **[[Solidsciencemethods-001:1.09transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

+ **[[Solidsciencemethods-001:1.09nfernandes | Approaches]]** by [Nuno Fernandes](https://class.coursera.org/solidsciencemethods-001/forum/profile?user_id=5612778)

[[File:approaches.png|400px|thumb|center|Approaches]]

<span style="color:white;">.</span>

##1.10 Goal

+ **[[Solidsciencemethods-001:1.10transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)


<span style="color:white;">.</span>

<span style="color:white;">.</span>


#Module 2: The scientific method

+ **[Video Lecture Transcripts - Module 2 (download link)](https://copy.com/DkUj7MGVD6tkxh8z)**

<span style="color:white;">.</span>


##2.01 The empirical cycle

+ **[[Solidsciencemethods-001:2.01nfernandes | The Empirical Cycle]]** by [Nuno Fernandes](https://class.coursera.org/solidsciencemethods-001/forum/profile?user_id=5612778)

[[File:Empirical_cycle.png|400px|thumb|center|The empirical cycle]]


<span style="color:white;">.</span>

##2.02 (Dis)confirmation

+ **[[Solidsciencemethods-001:2.02transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##2.03 Criteria

+ **[[Solidsciencemethods-001:2.03transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##2.04 Causality

+ **[[Solidsciencemethods-001:2.04transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##2.05 Internal validity threats: participants

+ **[[Solidsciencemethods-001:2.05transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##2.06 Internal validity threats: instruments

+ **[[Solidsciencemethods-001:2.06transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##2.07 Internal validity threats: artifacts

+ **[[Solidsciencemethods-001:2.07transcript | Video Lecture Transcript]]** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##2.08 Internal validity threats: design/procedure

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/208_internal_validity_threats-design_procedure.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##2.09 Variables of interest

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/209_variables_of_interest.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##2.10 Variables of desinterest

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/210_variables_of_disinterest.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

#Module 3: Research designs

+ **[Video Lecture Transcripts - Module 3 (download link)](https://copy.com/s0in9gGsEVVxVyeO)**

<span style="color:white;">.</span>


##3.01 The empirical cycle

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/301_true_experiments.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##3.02 Factorial designs

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/302_factorial_designs.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##3.03 Repeated measurement

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/303_repeated_measures.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##3.04 Manipulation

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/304_manipulation.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##3.05 Lab vs. field

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/305_lab_vs_field.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>


##3.06 Randomization

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/306_randomization.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##3.07 Experimental designs

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/307_experimental_designs.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##3.08 Matching

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/308_matching.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>

##3.09 Quasi-experimental designs

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/309_quasi-experimental_designs.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>


##3.10 Correlational designs

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/310_correlation_designs.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)


<span style="color:white;">.</span>


##3.11 Other designs

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/311_other_designs.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)


<span style="color:white;">.</span>


#Module 4: Measurement

+ **[Video Lecture Transcripts - Module 4 (download link)](https://copy.com/f8oWNj0Qqje2qOA7)**

<span style="color:white;">.</span>


##4.01 Operationalization

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/401_operationalization.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

+ **[[Solidsciencemethods-001:4.01chrysanthitseloudi | Operationalization]]** by **Chrysanthi Tseloudi**



##4.02 Measurement structure

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/402_measurement_structure.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)


<span style="color:white;">.</span>


##4.03 Measurement levels

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/403_measurement_levels.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>



##4.04 Variable types

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/404_variable_types.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>


##4.05 Measurement validity

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/405_measurement_validity.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

+ **[[Solidsciencemethods-001:4.05haodong | Convergent and discriminant validity ]]** by [Hao Dong](https://class.coursera.org/solidsciencemethods-001/forum/profile?user_id=5963098) Credit to [Mirjam](https://class.coursera.org/solidsciencemethods-001/forum/profile?user_id=3780448)

<span style="color:white;">.</span> 


##4.06 Measurement reliability

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/406_measurement_reliability.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>



##4.07 Survey, questionnaire, test

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/407_survey_questionnaire_test.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>


##4.08 Scales & response options

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/408_scales_and_response_options.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>



##4.09 Response and rater bias

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/409_response_and_rater_bias.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)
<span style="color:white;">.</span>

+ **[[Solidsciencemethods-001:4.09chrysanthitseloudi | Response and rater bias: excerpts of lecture transcript]]** by **Chrysanthi Tseloudi**



##4.10 Other measurement types

+ **[Video Lecture Transcript](https://d396qusza40orc.cloudfront.net/solidsciencemethods/Video%20lecture%20transcripts/410_other_measurement_types.pdf)** by [Annemarie Zand Scholten](https://www.coursera.org/instructor/annemarie)

<span style="color:white;">.</span>
###Physical Measures
>Examples:

>* electrical skin conductance to measure arousal
>* eye tracking to measure focus of attention
>* EEG and fMRI to register brain activity
>* reaction times to assess cognitive ability.

_Frequently used in:_ biology, medicine, psychology.
###Observational Measurement
Observational measurement is not as easy as simply observing and recording all the behavior that you see. Systematic observation involves __careful registration of specific behavior__.

__Coding schemes__

Researchers employ coding schemes that specify categories of behavior and their criteria. They specify:

* what the behavior in each category __looks like__
* __how long__ it should be displayed
* under what __circumstances__ it should occur.

__Time frame to be coded:__ Will we view an entire hour of videotaped behavior or will we sample five two-minute intervals? If we have taped material of an hour for each of sixty participants, then the two-minute intervals might be a better idea!

__Training and calibration of observers:__ Coding schemes can be complex and target behavior can be difficult to spot. So it’s a good idea to have more than one observer and to train observers until they show enough agreement when coding the same material.

__Inter-rater reliability:__ Agreement between different observers should be high. If reliability is low then at least one of the observers codes the behavior differently from the rest. Or, even worse, the behavior cannot be interpreted consistently.

_Frequently used in:_ sociology, psychology, educational sciences.

###Trace Measurement
Indirect behavior assessment through physical trace evidence.

>Example:

>Counting the number of used tissues after a therapy session to represent how depressed a client is.

_Frequently used in:_ political sciences and sociology.
###Archival Data
Measurements that have been collected by others.

>Example:

>Use of census data, collected by a national research institute, on income and voting behavior. We could investigate whether areas with a higher average income are associated with more votes for conservative political parties.

_Frequently used in:_ political sciences and sociology.
###Content Analysis
Content analysis consists of structured coding of elements in a text. The text can consist of newspaper articles, blogs, narratives or transcription of interviews. This technique shares characteristics with observational, archival and trace measurement. 

>Example:

>Investigate if conservative and liberal politicians argue differently, by identifying the number of emotional and rational words they use in newspaper interviews. Of course this is a simple example.

Text can be coded automatically according to very complex schemes using computer software.
###Interview
>####Structured Interview
>The questions, the question order and response options are pre-determined.

>This type of interview - be it face-to-face, through telephone or Skype - is not much different from using a survey. The response rate of interviews is higher, but it can be more difficult to get unbiased answers to sensitive questions.
>####Unstructured/ Open Interview
>An open interview is considered a qualitative method and is used very often.

>In an open interview the interviewer starts off with a general topic and usually has a set of points to be addressed but the interview is not limited to these points.

>Questions are open-ended and there is little structure, so the conversation can lead anywhere depending on the respondent's answers. The questions that will come up and the range of answers are undetermined. Of course this makes it much harder to compare and aggregate data from different respondents.
###Case Study
###Focus Groups
###Oral History
###Participatory Observation

#Module 5: Sampling

+ **[Video Lecture Transcripts - Module 5 (download link)](https://copy.com/B0jYf7L0PbUapgb1)**

<span style="color:white;">.</span>

##Extrenal Validity Threats
External validity, or generalizability, refers to **whether the hypothesized relation holds for other persons, settings and times**. Just like with internal validity, there are a number of threats to external validity.
###History Threat
A history threat means that the observed effect **doesn't generalize to other time periods**.
>Example:

>Consider a compliance study performed in the nineteen fifties in the US. Results showed that participants were willing to comply with highly unethical directions provided by an authoritarian experimenter. These results would probably be less extreme if we repeated the study nowadays, for example because people are more highly educated and less sensitive to authority than in the nineteen fifties.
###Setting Threat
A setting threat to external validity means that the observed effect only holds in a specific setting. The findings **do not generalize to other environments or situations**.
>Example:

>Suppose we investigate the relation between violent imagery and aggression and find that children who watch a violent video are more aggressive afterwards in the school playground. A setting threat occurs if this effect depends on the surroundings, for example if children are not more aggressive when they play at home under their caregiver's supervision.

There are **two setting threats associated with the artificiality of the research setting**
specifically. These threats are pretesting and reactivity.
####Pretesting Threat
A pretesting threat means that **the observed effect is found only when a pretest is performed**. This threat is closely related to the internal validity threat of testing.

>Example: Say we investigate a new therapy for treating depression and use a pretest. Suppose the depression pretest makes participants realize how serious their problems are, and thereby makes them more receptive to the treatment. The treatment is effective, but only if receptiveness is increased by the pretest first. In this case internal validity is threatened because 'receptiveness' is missing from our hypothesis. External validity is also threatened, because the hypothesis will only apply to situations where a pretest is part of the setting.
####Reactivity
A reactivity threat occurs when the participants or experimenter react to the fact that they are participating in a research study. Reactivity includes participant and experimenter expectancy and altered participant behavior, for example due to nervousness. This can cause the hypothesized relation to **occur only in a research setting and not in a in a natural setting**.
>Example:

>Say we investigate a new method for teaching high school math. The researcher is present during the lessons and measures math performance in class. What if students work harder because they know they are being studied and this makes the new method more effective? In a natural setting, without the researcher present, students might put less effort in their schoolwork, reducing the effectiveness of the new method.
###Selection
Selection is a very important threat to external validity. A selection threat occurs when **the hypothesized relation only holds for a specific subset of people** or if the results in our study are **biased due to over- or underrepresentation of a certain subset**.
>Examples:

>* Suppose that in our study on a new depression therapy, we recruited participants who actively volunteered. Say we find that the therapy method is effective. Of course our volunteers might be more proactive about solving their problems than the average person. It is entirely possible that the method is ineffective for people who are less proactive. The overrepresentation of volunteers might lead to an overestimation of the therapy's effectiveness.*
>* Suppose we want to know people's opinion on women's right to vote and we interview people on a university campus. The sample is now so selective that it is highly unlikely that results will generalize to the general public's opinion.

What can we do about these threats to external validity? History and setting threats to external validity can be reduced by replicating a study in a different time or by repeating a study in different settings. In the case of threats related to the artificiality of the research setting specifically, this means repeating a study in a more natural environment. Replication can also reduce the threat of selection to external validity, in this case by repeating a study with different groups of subjects. But there is another way to reduce the threat of selection. This is random sampling of the research sample, also referred to as probability sampling.

##Sampling Concepts
###Population
The term population refers to **the entire collection of people or groups to whom the hypothesis is supposed to apply**. Researchers should define their target population explicitly. Does the hypothesis apply to all people in the entire world, or just people in a specific country or culture?
>Examples:

>* Consider the hypothesis "Loneliness causes an increase in depression". This is a typical universalistic hypothesis. If the population is not explicitly mentioned, we infer the relation is assumed to hold for all people, in all cultures, in the past, now and in the future.
>* "Patriotism is steadily declining in the Netherlands over the last five years". This is at typical particularistic hypothesis. It is clear that this hypothesis applies to a specific country and to a specific time.

Let's assume that the target population for a hypothesis is clearly defined. How can we determine if the results generalize to this entire population?

If we measure the entire population, then we're automatically sure the results hold for the entire population. Of course, for universal hypotheses it's simply impossible to measure the entire population, because the population consists of all people everywhere, including all people who are long dead and all people who have yet to be born. Even if the target population is smaller and well defined, it is almost always too complicated and too expensive to include the entire population in a study.

This is why we take a **sample**.
###Sample
A sample is a **subset of the population**. The sample is used to represent or estimate a property of the population. We have to make sure that our sample **represents the population accurately**. The overrepresentation of a specific part of the population can weaken the study's external validity.

>Overrepresentation Examples:

>* Suppose we sample mostly elderly people in our study on the effect of loneliness on depression and we find a strong effect.  Perhaps the strong effect of loneliness on depression is less apparent for young people. If our sample had been more representative of the entire population we would have found a smaller effect.

>* The same goes for our study of decreased patriotism. Suppose our sample consisted mainly of highly educated people working at a university. This might lead us to underestimate patriotic attitudes in the Netherlands. Our results will be biased.

###Element
An element, or unit, is a **single entity** in the population. Together all the elements form the population. An element most often consists of one person, but of course it depends on your hypothesis. An element can also be a group, a school, a city, a union, a country; you name it.
###Stratum
A stratum is **a subset of elements from the population that share a characteristic**.
>Example:

>In the population of currently enrolled students from the University of Amsterdam we can distinguish a female and a male stratum, for example. Of course we can identify many different strata that may overlap, for example male and female undergraduate and graduate students.
###Census
The term census refers to **an enumeration or count of all elements in the population**. The term can also refer to a situation where all elements in the population are actually measured; in that case, the sample consists of the entire population. The term census can indicate a 'national census': A nation-wide survey where demographic information on each inhabitant is collected. Of course in many western countries this census is conducted virtually, by collecting information from government databases.
###Sampling Frame
A sampling frame is essentially **a list of all the elements in a population that can be individually identified**. A sampling frame can overlap with a census defined as an enumeration of the population. However, a sampling frame is more than a simple list of elements. A sampling frame **provides a way of actually contacting elements**. It could be a phonebook or a list of email addresses for all students currently enrolled at the University of Amsterdam, for example. Also, a sampling frame **doesn't always include all elements of a population**. This could be **due to clerical errors or an outdated list**.


##Sampling Methods
Some sampling methods offer better protection against the selection threat to external validity than others do. 

###Probability Sampling
To use probability sampling, we need to have a sampling frame: a list of all elements in the population that can be accessed or contacted. **A sampling frame is necessary to determine each element's probability of being selected**. This probability should be known and non-zero. Then, some form of **random selection** is required where any element could in principle end up in the sample.

Probability sampling minimizes the threat of a systematic bias in our selection of participants. Reducing systematic bias means reducing the risk of over- or underrepresentation of any population subgroup with a systematically higher or lower value on the property. Otherwise, our sample value will be unlikely to represent the population value accurately.

To avoid a systematic difference between the sample and the population, we select elements from the population randomly.
In the long run **any specific participant characteristics will be represented in the sample, proportionally to their presence in the population**. This means that any characteristic associated with a systematically higher or lower score on the dependent variable cannot bias the results in the long run. We call this a **representative sample**.
  
>Example:

>Suppose a population consists of eighty percent women. With repeated random sampling, we can expect the sample to contain eighty percent women in the long run. Each individual element has the same probability to be selected, and since there are more women, female elements will be selected more often.

Probability sampling also allows us to **assess the accuracy of our sample estimate**. Probability sampling allows us to determine, that with repeated sampling, in a certain percent of the samples, **the sample value will differ** from the real, population value **by no more than a certain margin of error**. This means that we can judge how accurate our sample estimate is in the long run. Given a certain risk to get it wrong, we can assess what the margin of error is on average, meaning by how much the sample and population value will differ on average.

>Example:

>Consider an election between conservative candidate A and democratic candidate B. We want to estimate the proportion of people in the population that will vote for candidate A as accurately as possible. Random sampling allows us to make statement such as this: If we were to sample voters repeatedly, then in ninety percent of the samples, the true, population proportion of votes for A would lie within eight percentage points of our sample estimate. So if we find that sixty percent of our sample indicates they will vote for A, then we can say we are fairly confident that the true proportion will lie somewhere between fiftytwo and sixty-eight percent. This interval is called a **confidence interval**. Of course this particular interval could be wrong, because in ten percent of the samples the sample value will lie further that eight percentage points from the true value. This could be one of those samples, so we can never be certain.

There are several types of probability sampling. 
####Simple Random Sampling (Simple)
Simple random sampling is **the most basic form of probability sampling**. In simple random sampling **each element in the sampling frame has an equal and independent probability of being included** in the sample. Independent means the selection of any single element does not depend on another element being selected first. In other words, every possible combination of elements is equally likely to be sampled.

To obtain a simple random sample, we could write every unique combination of sampled elements on a separate card, shuffling the cards and then blindly drawing one card. Of course, if the population is large, then writing out all possible combinations is just too much work. Fortunately, an equivalent method is to randomly select individual elements. This can be done using random number tables, still found in the back of some statistics books. But these tables have become obsolete; we can now **generate random number sequences with a computer**. For example, if our population consists of twelve million registered taxpayers, then we can generate a sequence of two hundred unique random numbers between one and twelve million.


####Systematic Sampling (Simple)
Systematic sampling is also **aimed to obtain a random sample** and is similar to simple random sampling. In systematic sampling **only the first element is selected using a random number, the other elements are selected by systematically skipping a certain number of elements**.
>Example:

>Suppose we want to sample the quality of cat food on an assembly line. A random number gives us a starting point: say the seventh bag. We then sample each tenth bag, so we select bag number seven, seventeen, twenty-seven, etcetera. It would be much
harder to select elements according to random numbers, say bag number seven, thirty, thirty-six, forty-one etcetera., especially if the assembly line moves very fast.

With this approach, **each element has an equal probability of being selected, but the probabilities are not independent**. 
>In our example, elements seventeen, twenty-seven, thirty-seven etcetera, are only chosen if seven is chosen as a starting point.

This is not a real problem; it just requires a little more statistical work to determine things like the margin of error.
The **real problem** with systematic sampling is that **it only results in truly random sample if there is absolutely no pattern in the list of elements**.
>What if the assembly line alternately produces cat food made with fish and cat food made with beef? Let's say all odd-numbered elements are made with fish. In our example we would never sample the quality of cat food made with beef! Of course this is an exaggerated example, but it illustrates that systematic sampling can be dangerous.

A pre-existing list or ordering of elements can always contain a pattern that we are unaware of, resulting in a biased sample.
So systematic sampling only results in a truly random sample if it is absolutely certain that the list of elements is ordered randomly. We can **make sure of this by randomly reordering the entire list**. We could generate a sequence of random numbers of the same size as the list and then select elements from this list using systematic sampling. Of course this is equivalent to random selection directly from the original list using random numbers. Unless we can be sure that the list is truly random, systematic sampling should not be considered a form of probability sampling; instead it should be considered **a form of non-probability sampling**.

####Stratified Random Sampling (Relatively Simple)
In stratified random sampling we **divide the population into mutually exclusive strata**. We sample from each stratum separately using **simple random sampling**. The separately sampled elements are **added together** to form the final sample.

Stratified random sampling is useful for two reasons.

* It allows us to ensure that at least in terms of the sampled strata, **our sample is representative**. This means subpopulations are represented in the sample in exactly the same proportion as in the population. With simple random sampling we can expect the sample to be representative in the long run, but due to chance, in any particular sample, strata might be over- or underrepresented.*

* Stratification is useful because it can make **sampling more efficient**. This means, all other things being equal, that we achieve a **smaller margin of error** with the same sample size. Stratifying only increases efficiency if the strata differ strongly from each other, relative to the differences within each stratum.*

>Example:

>Imagine we want to sample the quality of cat food produced on an assembly line. The line produces cat food made with fish and cat food made with beef. Suppose the average quality of beef cat food is higher than that of fish cat food. Also, the quality
varies relatively little when we consider each type of food separately. Under these circumstances we will obtain a more accurate estimate of the population's average food quality if we stratify on food type. This is because quality is related to food type; even a small overrepresentation of one food type can distort our overall estimate of food quality. Stratifying prevents this distortion. If the quality does not differ between food types, then overrepresentation of one food type will not distort the overall estimate and stratification will not improve efficiency.

It is important to realize that stratified sampling requires that we know which stratum each element belongs to. If we can identify strata, then we also know their size. As a consequence, the size of our subsamples does not have to correspond to the size of the strata. We can calculate a representative estimate by weighing the subsamples according to stratum size.
>Example:

>Why would we do this? Well, suppose our stratum of fish cat food is relatively small, or is known to strongly vary in quality. In both cases our estimate of the quality of fish cat food might be much less likely to be accurate than that of beef cat food. It might be worth it to take a bigger sample of fish cat food, so we have a better chance of getting an accurate estimate. Of course this means over-representing fish cat food. We can correct for this overrepresentation by weighing the separate estimates of fish and beef cat food according to their stratum sizes before averaging them into an overall estimate of food quality. This way the sample value is representative, efficient and more likely to be accurate.

#####Multi-Stage Cluster Sampling (Relatively Simple)
Multi-stage cluster sampling consists of **randomly sampling in stages**, allowing us to use random sampling without going bankrupt. 

>Example:

>Consider sampling frames that consist of all inhabitants, students, or eligible voters in a certain country. If we were to randomly select elements from these frames we would have to travel all over the country. In most cases this is just too expensive.

>Say we want to sample math performance in the population of all Dutch students currently in their third year of secondary education. We start by forming a **sampling frame of all** school districts; this is the first stage, where students are clustered in districts. We randomly select a very small sample of school districts. We can use **stratification** to make sure we include districts in urban and rural areas.

>In the second stage we **randomly select** schools from the previously selected districts. Students are now clustered in schools. In the third stage third year math classes are randomly sampled from the previously selected schools. We could even include a fourth stage where students are randomly sampled from the previously selected classes. Stratification can be used in all of these stages.

Multi-stage cluster sampling **makes random sampling feasible**. But the margin of error is harder to determine, because the probability to be included in the sample is no longer the same for all elements, like it was with simple random sampling. Also, cluster sampling is usually associated with a **larger margin of error**, even if stratified sampling is used to increase efficiency. However, these disadvantages are generally more than outweighed by the **reduction in cost and effort**.

###Non-Probability Sampling
In non-probability sampling some elements in the sampling frame either have zero probability to be selected or their probability is unknown. As a consequence, we cannot accurately determine the margin of error. It's also impossible to determine the likelihood that a sample is representative of the population. If a study uses non-probability sampling, the results should always be interpreted with **great caution** and generalized only with very great reservation.

####Convenience Sampling
Convenience sampling, or accidental sampling, is the simplest form of non-probability sampling. In convenience sampling, **elements are selected that are the most convenient, the most easily accessible**.

>Example:

>If I'm interested in investigating the effectiveness of online lectures on study performance, I could recruit students in
courses that I teach myself. Of course this a highly selective sample of students from a particular university in a
particular bachelor program. Results will almost certainly be influenced by specific characteristics of this group and might very well fail to generalize to all university students in my country, let alone students in other countries.

So the risk of bias is high and we have no way to determine how closely the sample value is likely to approach the population value. Even so, convenience samples are used very often. Because sometimes, it's simply impossible to obtain a sampling frame.
In other cases, the effort and expense necessary to obtain a sampling frame are just not worth it; for example when a universalistic, causal hypothesis is investigated.


####Snowball Sampling
Snowball sampling is a **specific type of convenience sampling**. In snowball sampling, initially, **a small group of participants is recruited**. The sample is extended by asking the initial participants to provide contact information for possible new participants. These new participants are also asked to supply contacts. If all **participants refer new ones**, the initially small sample can grow large very quickly.
>Example:

>Suppose we want to sample patients who suffer from a rare type of cancer. We could approach a patient interest group, for example, and ask the initial participants if they can put us in contact with other patients that they know through other interest groups or through their hospital visits. We continue to ask new participants to refer others to us, until the required sample size is reached.

Snowball sampling is very useful for hard-to-reach, closed-community populations. All disadvantages of convenience sampling also apply to snowball sampling, maybe even more so, because there is the added risk that we are selecting a clique of friends, colleagues or acquaintances. These **people could share characteristics that differ systematically from others** in the population.

####Purposive Sampling
In purposive sampling, elements are specifically **chosen based on the judgment of the researcher**. A purposive sample can consist of elements that are judged to be:

* __typical for the population__, so that only a few elements are needed to estimate the population value.*
* __only extreme elements__, for example, to get an idea of the effectiveness of social workers working with extremely uncooperative problem families*
* elements that are __very much alike__, or, 
* __very different__, for example, to get an idea of the range of values in the population*
* people who are judged to be __experts__, for example when research concerns opinions on matters that require special knowledge.*

Purposive sampling is used mostly in qualitative research and suffers all the same disadvantages that convenience sampling does. The researcher's judgments can even form an additional source of bias.

####Quota Sampling
Quota sampling is superficially similar to stratified random sampling. **Participants in the sample are distinguished according to characteristics**, such as gender, age, ethnicity or educational level. The relative size of each category in the population can be obtained from a national statistics institute. This information is used to calculate how many participants are needed in each category. So that **the relative category size in the sample corresponds to the category size in the population**. But instead of randomly selecting elements from each stratum, **participants for each category are selected using convenience sampling**. Elements are sampled until the quotas in all categories are met.
Although this approach might seem to result in a representative sample, all kinds of biases could be present.
>Bias Example:

>Suppose the choice of participants is left to an interviewer. Then it's possible that only people who seem friendly and cooperative are selected.

##Errors
The goal of sampling is to estimate a value in the population as accurately as possible. But even if we use the most advanced sampling methods, there will always be some discrepancy between our sample value - the estimate - and the true value in the
population. The **difference between sample and population value** is generally referred to as error. This error can be categorized into two general types sampling error and non-sampling error.
###Sampling error
Sampling error is the difference between population and sample value due to the fact that our sample is a **limited, incomplete subset** of the population.

The true value in the population is almost always unknown. If we knew the population value then we wouldn't need a sample. This also means that for any particular sample we cannot assess how large the error is exactly. However, for sampling error it is **relatively easy to estimate how large the error is**. If we would take an infinite number of samples from a population, then under certain conditions, the average sample value of all these samples will correspond to the population value.
But of course individual samples will result in sample values that are different from the population value. Sampling error is the **difference between sample and population value that we would expect due to chance**. We can estimate how large the sampling error is on average, if we were to repeatedly draw new samples from the same population. Note that this only works for randomly selected samples!

The average error, called the **standard error**, can be estimated based on the values obtained in a single sample. We can then use the standard error to calculate a margin of error.

You might think the margin of error tells us by how much our sample differs from the population at most. But we can't calculate between what boundaries the true population value lies exactly, because we are estimating the sampling error in the long run, over repeated samples. In the long run a ridiculously small or large value is always possible. What we can say is that **the population value will lie between certain boundaries most of the time**. This information is captured in a **confidence interval**. A confidence interval allows us to say that with repeated sampling, in a certain percentage of these samples, the true population value will differ from the sample value by no more than the margin of error.

>Example:

>Suppose we want to estimate the proportion of people that will vote for candidate A in an election. We sample one hundred eligible voters and find that sixty percent of the sample says they'll vote for A. We have to decide how confident we want to be. Let's say that with repeated sampling, we want the population value to fall within the margin of error at least ninety percent of the time. With this decision, we can now calculate the margin of error. Let's say that the margin of error is eight percent. This means we can say that with repeated sampling, the population value will differ from the sample value by no more than eight percent, in ninety percent of the samples.

Sampling error is **related to the sample size**. As sample size increases, sampling error will become smaller. Sampling error is also influenced by the **amount of variation in the population**. If a population varies widely on the property of interest, then the sample value can also assume very different values. For a given sample size, sampling error will be larger in a population that shows more variation.

_**Summary**: Sampling error is the difference between population and sample value due to chance, due to the fact that our sample is a limited, incomplete subset of the population. Sampling error is unsystematic, random error. It is comparable to the random error that makes a measurement instrument less reliable. We can estimate how large the sampling error will be in the long run, which allows us to conclude how accurate our sample value is likely to be. This only works under certain conditions. One of these conditions is that the sample is a random sample from the population._

###Non-Sampling Error
Non-sampling error is the difference between population and sample value **due to sources other that sampling error**. Two major sources of non-sampling error are sampling bias and error due to nonresponse. They are both related to the sampling procedure.

####Sampling Bias
Sampling bias is a systematic form of error. Sampling bias is the difference between sample and population value **due to a systematic under- or overrepresentation** of certain elements in the population. Sampling bias occurs when some elements have a **much smaller or larger chance to be selected than was intended**. Sampling bias can also occur when certain elements have **no chance to be selected** at all.
>Example:

>Suppose we want to estimate the proportion of people that will vote for candidate A in an election. Sampling bias could occur if participants were recruited on the street by an interviewer during working hours. This could lead to an underrepresentation of people who are employed full-time. If these people would vote for candidate A more often, then we would systematically underestimate the percentage of votes for candidate A.

The risk of sampling bias is **eliminated**, at least in the long run **by using a probability sampling method**. With non-probability sampling, the risk of sampling bias is strong. Sampling bias is comparable to the systematic error that makes a measurement instrument less valid, or less accurate.
####Non-Response
Non-response is the source of error that refers to a **lack of response to invitations** or the **explicit refusal** to participate in a study. Non-response also includes participants who **drop out during the study** or **participants whose data are invalid** because they did not participate seriously, because something went wrong or they did not understand or failed to comply with some aspect of the procedure.
If non-response is **random**, then you could say that non-response results in a **smaller sample** and will thereby **slightly increase the margin of error**. But sometimes nonresponse is **not random**. Sometimes specific subgroups in the population are less likely to participate. If this subgroup has systematically different values on the property of
interest, then **non-response is a source of systematic error**.

>Example:

>Suppose people with a lower social economic status are less likely to participate in polls and also prefer other candidates to candidate A. In that case we are missing responses of people that would not vote for A, which could lead to a systematic
overestimation of the percentage of people that will vote for A.

####Incomplete/ Inaccurate Sampling Frame
>Example:

>The sampling frame might be out of date.

##Sample Size
The goal of sampling is to obtain the best possible estimate of a population value, within the limits of our budget and our time.
Sample size refers to the number of elements we need to sample in order to get an accurate estimate of the population value.

An easy answer would be "as large a sample as we can afford". Because as sample size increases, the margin of error will decrease. Accidental over- or underrepresentation of certain elements will be less extreme and will become less likely. In other words, **a bigger sample is always better in terms of accuracy**.

But this doesn't mean we should all collect samples consisting of tens of thousands of elements. This is because as the sample size grows, the decrease in the margin of error becomes smaller and smaller. At a certain point **the cost of collecting more elements outweighs the decrease in the margin of error**.

>Example:

>Say we want to estimate the proportion of votes for candidate A in upcoming elections. Suppose we have a sample of five hundred eligible voters. Then the error won't be cut in half if we double the sample to a thousand elements, the decrease in error will be much, much smaller.

Note that it is **the absolute size** of the sample that **matters**, not the relative size. It doesn't matter if we are estimating election results in Amsterdam, with slightly more than half a million eligible voters, or national elections with more than 13 million voters. As long as the samples are both randomly selected, the margin of error will be the
same, all other things being equal. This seems very counter-intuitive, but it's true nonetheless.

There are other **factors to consider** when deciding on sample size. The **variability** of the population is an important factor. Heterogeneity, or strong variation in the population on the property of interest, results in a larger margin of error, all other things being equal. If values in the population vary widely, then a sample is more likely to accidentally over- or underestimate the true population value. If the population is more homogeneous or similar, meaning it takes on a narrow, limited set of values, well then the sample value will automatically lie close to the population value. If a population is more homogeneous, we can sample more efficiently. This means, all other things being equal, that we can achieve a smaller
margin of error with the same sample size. Or, conversely, we can obtain the same margin of error with a smaller sample.

If a probability sampling method is used we can **determine what margin of error we are willing to accept**, given a certain confidence level. We can say that we want our sample estimate of election results to differ by no more than five percent from the final results in ninety five percent of the samples, if we were to sample repeatedly. We, or rather a computer, can now calculate exactly what sample size we need, to obtain this margin of error at this confidence level. This does require that we use random sampling and that we can estimate the variability in the population, for example based on previous studies, old census data or just a best guess if necessary.

It's a good idea to **plan ahead and compensate for non-response**. Non-response refers to elements in the sample that cannot be contacted, that refuse to participate, fail to complete the study or provide invalid responses. If the response-rate can be estimated based on previous or comparable research, then we can take non-response into account and **sample extra elements** that will compensate for the expected loss of elements due to non-response.

<span style="color:white;">.</span>

#Module 6: Practice, ethics & integrity

+ **[Video Lecture Transcripts - Module 6 (download link)](https://copy.com/iNtufXKum09RzGQy)**

<span style="color:white;">.</span>

[[Category: Solid Science: Research Methods]]
